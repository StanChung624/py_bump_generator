from typing import Callable, List, Dict

from VBump.Basic import VBump, _require_h5py, _require_numpy

def make_move_func(dx, dy, dz, *,
                   new_group:int|None=None,
                   new_D:float|None=None,
                   group_map:Dict[int,int]|None = None,
                   keep_original:bool=False):
    
    def move_and_duplicate(row):
        original = row.copy()
        moved = row.copy()
        moved['x0'] += dx
        moved['x1'] += dx
        moved['y0'] += dy
        moved['y1'] += dy
        moved['z0'] += dz
        moved['z1'] += dz        
        if new_D is not None:
            moved['diameter'] = new_D

        if group_map and moved['group'] in group_map:
            moved['group'] = group_map[moved['group']]
        elif new_group is not None:
            moved['group'] = new_group
        
        if keep_original:
            return [original, moved]
        else:
            return [moved]
    return move_and_duplicate

def modify_vbump_hdf5(
    src_path: str,
    dst_path: str,
    *,
    modify_func: Callable[[dict], List[dict]],
    chunk_size: int = 1_000_000,
    dataset_name: str = "vbump",
    output_name: str | None = None
) -> None:
    """
    Copy vbump dataset, apply modify_func to each row,
    and update each group's bounding_box accordingly.
    """

    h5py = _require_h5py()
    np = _require_numpy()

    with h5py.File(src_path, 'r') as fin, h5py.File(dst_path, 'w') as fout:
        # === Step 1. Ê™¢Êü•ÂéüÂßã dataset ===
        if dataset_name not in fin:
            raise KeyError(f"Dataset '{dataset_name}' not found.")
        dset_in = fin[dataset_name]
        dtype = dset_in.dtype
        total = dset_in.shape[0]
        print(f"üìà Source rows: {total:,}")

        target_dataset_name = output_name or dataset_name

        # === Step 2. Âª∫Á´ãËº∏Âá∫ dataset ===
        dset_out = fout.create_dataset(
                            target_dataset_name,
                            shape=(0,),
                            maxshape=(None,),
                            dtype=dtype,
                            chunks=True
                        )
        print(f"üì¶ Created '{target_dataset_name}'")

        # === Step 3. Ë§áË£Ω groups Êû∂ÊßãÔºà‰ΩÜÁ®çÂæåÊúÉÊõ¥Êñ∞ bboxÔºâ ===
        if 'groups' in fin:
            fin.copy('groups', fout)
            fout_groups = fout['groups']
        else:
            fout_groups = fout.create_group('groups')

        # === Step 4. Âª∫Á´ã group bbox Êö´Â≠òÂô® ===
        group_bbox = {}  # {gid: [xmin, ymin, zmin, xmax, ymax, zmax]}
        overall_bbox: list[float] | None = None

        # === Step 5. ÂàÜ chunk ËôïÁêÜ ===
        for start in range(0, total, chunk_size):
            end = min(start + chunk_size, total)
            arr = dset_in[start:end]
            new_rows = []

            for row in arr:
                r = {name: row[name].item() for name in row.dtype.names}
                result_list = modify_func(r)

                for new_r in result_list:
                    new_row = tuple(new_r[name] for name in row.dtype.names)
                    new_rows.append(new_row)

                    # Êõ¥Êñ∞ bounding box
                    gid = int(new_r['group'])
                    x_list = [float(new_r['x0']), float(new_r['x1'])]
                    y_list = [float(new_r['y0']), float(new_r['y1'])]
                    z_list = [float(new_r['z0']), float(new_r['z1'])]

                    x_min, x_max = min(x_list), max(x_list)
                    y_min, y_max = min(y_list), max(y_list)
                    z_min, z_max = min(z_list), max(z_list)

                    if gid not in group_bbox:
                        group_bbox[gid] = [x_min, y_min, z_min, x_max, y_max, z_max]
                    else:
                        bbox = group_bbox[gid]
                        bbox[0] = min(bbox[0], x_min)
                        bbox[1] = min(bbox[1], y_min)
                        bbox[2] = min(bbox[2], z_min)
                        bbox[3] = max(bbox[3], x_max)
                        bbox[4] = max(bbox[4], y_max)
                        bbox[5] = max(bbox[5], z_max)

                    if overall_bbox is None:
                        overall_bbox = [x_min, y_min, z_min, x_max, y_max, z_max]
                    else:
                        overall_bbox[0] = min(overall_bbox[0], x_min)
                        overall_bbox[1] = min(overall_bbox[1], y_min)
                        overall_bbox[2] = min(overall_bbox[2], z_min)
                        overall_bbox[3] = max(overall_bbox[3], x_max)
                        overall_bbox[4] = max(overall_bbox[4], y_max)
                        overall_bbox[5] = max(overall_bbox[5], z_max)

            # ÂØ´ÂÖ•Êñ∞ chunk
            arr_out = np.array(new_rows, dtype=dtype)
            if start == 0:
                dset_out.resize((len(arr_out),))
                dset_out[:] = arr_out
            else:
                old_size = dset_out.shape[0]
                new_size = old_size + len(arr_out)
                dset_out.resize((new_size,))
                dset_out[old_size:new_size] = arr_out

            print(f"‚úÖ Chunk {start:,}‚Äì{end:,} : {len(arr_out):,} rows (duplicated)")

            del arr
            del arr_out

        # === Step 6. ÂØ´ÂõûÊõ¥Êñ∞ÂæåÁöÑ bounding_box ===
        for gid, bbox in group_bbox.items():
            if str(gid) not in fout_groups:
                subgroup = fout_groups.create_group(str(gid))
            else:
                subgroup = fout_groups[str(gid)]
            subgroup.attrs['bounding_box'] = (
                (bbox[0], bbox[1], bbox[2]),
                (bbox[3], bbox[4], bbox[5])
            )

        if overall_bbox is not None:
            dset_out.attrs['bounding_box'] = (
                (overall_bbox[0], overall_bbox[1], overall_bbox[2]),
                (overall_bbox[3], overall_bbox[4], overall_bbox[5]),
            )

        print(f"üéØ Updated {len(group_bbox)} group bounding boxes.")

def merge_hdf5(
    src_paths: List[str],
    dst_path: str,
    *,
    dataset_name: str = "vbump",
    output_name: str | None = None,
    chunk_size: int = 1_000_000
) -> None:
    """
    Merge multiple vbump HDF5 datasets into one file.
    Preserve 'groups' structure and recompute bounding boxes.
    """
    h5py = _require_h5py()
    np = _require_numpy()

    # === Step 1. Âª∫Á´ãËº∏Âá∫Ê™îÊ°à ===
    with h5py.File(dst_path, 'w') as fout:
        target_dataset_name = output_name or dataset_name
        dset_out = None
        group_bbox: dict[int, list[float]] = {}
        overall_bbox: list[float] | None = None

        for path in src_paths:
            with h5py.File(path, 'r') as fin:
                if dataset_name not in fin:
                    print(f"‚ö†Ô∏è Skip '{path}', dataset '{dataset_name}' not found.")
                    continue

                dset_in = fin[dataset_name]
                dtype = dset_in.dtype
                total = dset_in.shape[0]
                print(f"üìÇ Merging {path} ({total:,} rows)")

                # Ëã•Á¨¨‰∏ÄÂÄãÊ™îÊ°àÔºåÂª∫Á´ãËº∏Âá∫ dataset
                if dset_out is None:
                    dset_out = fout.create_dataset(
                        target_dataset_name,
                        shape=(0,),
                        maxshape=(None,),
                        dtype=dtype,
                        chunks=True
                    )

                # === Step 2. ÂàÜ chunk ËÆÄÂèñËàáÂØ´ÂÖ• ===
                for start in range(0, total, chunk_size):
                    end = min(start + chunk_size, total)
                    arr = dset_in[start:end]

                    # Êõ¥Êñ∞ group bbox
                    for row in arr:
                        gid = int(row['group'])
                        x_list = [float(row['x0']), float(row['x1'])]
                        y_list = [float(row['y0']), float(row['y1'])]
                        z_list = [float(row['z0']), float(row['z1'])]
                        x_min, x_max = min(x_list), max(x_list)
                        y_min, y_max = min(y_list), max(y_list)
                        z_min, z_max = min(z_list), max(z_list)

                        if gid not in group_bbox:
                            group_bbox[gid] = [x_min, y_min, z_min, x_max, y_max, z_max]
                        else:
                            bbox = group_bbox[gid]
                            bbox[0] = min(bbox[0], x_min)
                            bbox[1] = min(bbox[1], y_min)
                            bbox[2] = min(bbox[2], z_min)
                            bbox[3] = max(bbox[3], x_max)
                            bbox[4] = max(bbox[4], y_max)
                            bbox[5] = max(bbox[5], z_max)

                        if overall_bbox is None:
                            overall_bbox = [x_min, y_min, z_min, x_max, y_max, z_max]
                        else:
                            overall_bbox[0] = min(overall_bbox[0], x_min)
                            overall_bbox[1] = min(overall_bbox[1], y_min)
                            overall_bbox[2] = min(overall_bbox[2], z_min)
                            overall_bbox[3] = max(overall_bbox[3], x_max)
                            overall_bbox[4] = max(overall_bbox[4], y_max)
                            overall_bbox[5] = max(overall_bbox[5], z_max)

                    # ÂØ´ÂÖ•Êñ∞ chunk
                    old_size = dset_out.shape[0]
                    new_size = old_size + len(arr)
                    dset_out.resize((new_size,))
                    dset_out[old_size:new_size] = arr

                    print(f"‚úÖ {path} Chunk {start:,}-{end:,}")

                # === Step 3. Âêà‰Ωµ groups ===
                if 'groups' in fin:
                    if 'groups' not in fout:
                        fout_groups = fout.create_group('groups')
                    else:
                        fout_groups = fout['groups']

                    for gid, subgroup in fin['groups'].items():
                        if gid not in fout_groups:
                            fin.copy(f'groups/{gid}', fout_groups)

        # === Step 4. Êõ¥Êñ∞ bounding box ===
        if dset_out is not None:
            fout_groups = fout.get('groups', fout.create_group('groups'))
            for gid, bbox in group_bbox.items():
                if str(gid) not in fout_groups:
                    subgroup = fout_groups.create_group(str(gid))
                else:
                    subgroup = fout_groups[str(gid)]
                subgroup.attrs['bounding_box'] = (
                    (bbox[0], bbox[1], bbox[2]),
                    (bbox[3], bbox[4], bbox[5])
                )

            if overall_bbox is not None:
                dset_out.attrs['bounding_box'] = (
                    (overall_bbox[0], overall_bbox[1], overall_bbox[2]),
                    (overall_bbox[3], overall_bbox[4], overall_bbox[5])
                )

            print(f"üéØ Merged {len(src_paths)} files, {len(group_bbox)} group bboxes updated.")
        else:
            print("‚ö†Ô∏è No valid datasets merged.")